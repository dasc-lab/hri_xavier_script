# Human Robot Interaction Outreach Project with Augmented Reality Headset

## System Overview
The camera streams an aerial live video
to a hologram on Hololens 2, where the user would
have three options to move the ground robot. The first
option is to direct the robot to one desired location by
first selecting the location and subsequently clicking
the ’confirm’ button. Alternatively, the user would
select waypoints in a sequential order in a pre-
designed route. Finally, the user could also click
buttons that would make the robot perform specified
tasks such as ’spin’ or ’advance one meter’. The
interface displays the past and predicted route of the
robot on the hologram to reduce cognitive load and
improve user experience.
## Hardware Components
The system comprises a Jetson Xavier as the processing unit of the drone, a libRealSense Camera that will be strapped onto the drone, a Microsoft Hololens that the user will interact with, and a rover that will move according to the user's commands.

## Socket Communication
